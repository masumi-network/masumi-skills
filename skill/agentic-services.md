# Agentic Services API Standard (MIP-003)

Complete guide to building MIP-003 compliant agentic services and integrating with AI agent frameworks.

## Overview

An **Agentic Service** on the Masumi Network is a defined AI service that:
- Has a **specific input** schema
- Performs **autonomous work** using AI agents
- Returns a **defined output**
- Can be **discovered** via the registry
- **Charges a fee** for its services

Agentic Services can be purchased by humans (via clients) or by other Agentic Services (via function calling), creating a decentralized network of collaborating AI agents.

```
┌──────────────────────────────────────────────────────┐
│              Agentic Service Architecture             │
├──────────────────────────────────────────────────────┤
│                                                       │
│  MIP-003 Compliant API                               │
│  ├─ POST /start_job     (Create job)                │
│  ├─ GET  /status        (Check job status)          │
│  ├─ GET  /availability  (Health check)              │
│  └─ GET  /input_schema  (Get input format)          │
│                                                       │
│  Payment Integration                                 │
│  ├─ Masumi Payment Service                          │
│  ├─ Decision Logging (hash input + output)          │
│  └─ Dispute Resolution                              │
│                                                       │
│  Business Logic (Your Agent)                         │
│  ├─ CrewAI / AutoGen / LangGraph / PhiData         │
│  ├─ Custom AI Implementation                        │
│  └─ External Service Integration                    │
│                                                       │
└──────────────────────────────────────────────────────┘
```

## MIP-003: Agentic Service API Standard

### Why Standardization?

A standardized API ensures:
- **Interoperability**: Services work seamlessly with Masumi Network
- **Reliability**: Consistent behavior across all agents
- **Scalability**: Easy integration of new services
- **Transparency**: Uniform response formats for debugging

### Required Endpoints

All Agentic Services MUST implement these four endpoints:

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/start_job` | POST | Initiate a new job |
| `/status` | GET | Check job status and retrieve results |
| `/availability` | GET | Health check for service status |
| `/input_schema` | GET | Return expected input schema |

## Endpoint Specifications

### 1. POST /start_job

**Purpose**: Initiates a job on the agentic service with specific input data.

**Request Body**:
```json
{
  "input_data": [
    {
      "key": "dataset",
      "value": "product,sales\nWidget,1000\nGadget,1500"
    },
    {
      "key": "analysisType",
      "value": "descriptive"
    }
  ],
  "identifier_from_purchaser": "buyer-unique-id-123"
}
```

**Field Descriptions**:
- `input_data`: Array of key-value pairs matching the schema from `/input_schema`
- `identifier_from_purchaser`: Unique identifier from the buyer (used for payment tracking)

**Response**:
```json
{
  "job_id": "job-456",
  "identifier_from_seller": "seller-job-456",
  "blockchain_identifier": "blockchain-id-xyz",
  "payment_address": "addr1...",
  "amount_lovelace": 10000000,
  "status": "awaiting_payment"
}
```

**Important Flow**:
```
1. Receive /start_job request
2. Validate input_data against input_schema
3. Generate unique job_id
4. Create payment request via Masumi Payment Service
5. Store job in database with status "awaiting_payment"
6. Return payment details immediately
7. Start background polling for payment confirmation
```

**Error Responses**:
```json
// 400 Bad Request - Invalid input
{
  "error": "INVALID_INPUT",
  "message": "Field 'dataset' is required but missing",
  "details": {
    "field": "dataset",
    "expected": "string",
    "received": null
  }
}

// 500 Internal Server Error - Job creation failed
{
  "error": "JOB_CREATION_FAILED",
  "message": "Unable to create job due to internal error"
}
```

### 2. GET /status

**Purpose**: Retrieves the current status of a specific job and returns results when complete.

**Query Parameters**:
- `job_id` (required): The ID of the job to check

**Request**:
```
GET /status?job_id=job-456
```

**Response (Awaiting Payment)**:
```json
{
  "job_id": "job-456",
  "status": "awaiting_payment",
  "payment_address": "addr1...",
  "amount_lovelace": 10000000,
  "created_at": "2026-02-20T17:00:00Z"
}
```

**Response (Running)**:
```json
{
  "job_id": "job-456",
  "status": "running",
  "progress": {
    "current_step": "Processing data",
    "percentage": 45
  },
  "estimated_completion": "2026-02-20T17:02:00Z"
}
```

**Response (Completed)**:
```json
{
  "job_id": "job-456",
  "status": "completed",
  "output": {
    "summary": {
      "totalProducts": 2,
      "totalSales": 2500,
      "averageSales": 1250
    },
    "details": {
      "topProduct": "Gadget",
      "bottomProduct": "Widget"
    }
  },
  "input_hash": "a3f5c8d91e...",
  "output_hash": "b7c2e9f04a...",
  "completed_at": "2026-02-20T17:01:30Z",
  "execution_time_seconds": 45
}
```

**Response (Failed)**:
```json
{
  "job_id": "job-456",
  "status": "failed",
  "error": "PROCESSING_ERROR",
  "message": "Failed to parse CSV dataset",
  "failed_at": "2026-02-20T17:00:45Z"
}
```

**Job Statuses**:
- `awaiting_payment`: Job created, waiting for payment confirmation
- `pending`: Payment received, job queued for execution
- `running`: Agent actively processing the job
- `completed`: Job finished successfully
- `failed`: Job failed with error
- `refunded`: Payment refunded to buyer

**Error Responses**:
```json
// 404 Not Found
{
  "error": "JOB_NOT_FOUND",
  "message": "No job exists with ID: job-456"
}
```

### 3. GET /availability

**Purpose**: Checks if the agentic service is operational (health check).

**Request**:
```
GET /availability
```

**Response (Available)**:
```json
{
  "status": "available",
  "message": "Service is operational",
  "uptime_seconds": 86400,
  "current_load": {
    "active_jobs": 5,
    "queued_jobs": 2,
    "max_capacity": 20
  },
  "estimated_wait_time_seconds": 0
}
```

**Response (Unavailable)**:
```json
{
  "status": "unavailable",
  "message": "Service is under maintenance",
  "estimated_downtime_seconds": 1800
}
```

**Use Cases**:
- Load balancing across multiple agents
- Network health monitoring
- Registry online/offline status
- User decision-making (avoid unavailable agents)

### 4. GET /input_schema

**Purpose**: Returns the expected input schema for the `/start_job` endpoint.

**Request**:
```
GET /input_schema
```

**Response**:
```json
{
  "type": "object",
  "properties": {
    "dataset": {
      "type": "string",
      "description": "CSV or JSON formatted dataset",
      "maxLength": 100000,
      "examples": [
        "product,sales\nWidget,1000\nGadget,1500"
      ]
    },
    "analysisType": {
      "type": "string",
      "enum": ["descriptive", "predictive", "diagnostic"],
      "description": "Type of analysis to perform",
      "default": "descriptive"
    },
    "outputFormat": {
      "type": "string",
      "enum": ["json", "markdown", "csv"],
      "description": "Format for the analysis results",
      "default": "json"
    }
  },
  "required": ["dataset", "analysisType"]
}
```

**Schema Format**: JSON Schema (Draft 7 compatible)

**Validation**: Clients MUST validate input before calling `/start_job`

## Decision Logging (MIP-004)

### What is Decision Logging?

Decision Logging is a cryptographic mechanism to prove that an Agentic Service delivered specific work:

- **Accountability**: Agents can't deny delivering what they did
- **Non-repudiation**: Agents can't claim they delivered something different
- **Privacy-preserving**: Only hash stored on blockchain, not actual data
- **Dispute resolution**: Buyers can prove invalid outputs

### Hashing Standard

#### Input Hash

```typescript
import crypto from 'crypto';
import canonicalize from 'canonicalize'; // RFC 8785

function hashInput(
  identifierFromPurchaser: string,
  inputData: any
): string {
  // Step 1: Canonical JSON serialization
  const canonicalJSON = canonicalize(inputData);

  // Step 2: Construct pre-image with semicolon delimiter
  const preImage = `${identifierFromPurchaser};${canonicalJSON}`;

  // Step 3: SHA-256 hash
  const hash = crypto
    .createHash('sha256')
    .update(preImage, 'utf-8')
    .digest('hex')
    .toLowerCase();

  return hash;
}

// Example
const inputHash = hashInput('buyer-123', {
  dataset: 'product,sales\nWidget,1000',
  analysisType: 'descriptive'
});
// Result: "a3f5c8d91e..."
```

#### Output Hash

```typescript
function hashOutput(
  identifierFromPurchaser: string,
  output: string
): string {
  // Step 1: Construct pre-image
  const preImage = `${identifierFromPurchaser};${output}`;

  // Step 2: SHA-256 hash
  const hash = crypto
    .createHash('sha256')
    .update(preImage, 'utf-8')
    .digest('hex')
    .toLowerCase();

  return hash;
}

// Example
const outputHash = hashOutput(
  'buyer-123',
  JSON.stringify({
    summary: { totalProducts: 2, totalSales: 2500 }
  })
);
// Result: "b7c2e9f04a..."
```

#### Combined Decision Hash

```typescript
const decisionHash = inputHash + outputHash;
// Result: "a3f5c8d91e...b7c2e9f04a..."

// Submit to Payment Service to unlock payment
await axios.post('/payment/submit-result', {
  identifier: 'job-456',
  decisionHash
});
```

### Why Semicolon Delimiter?

Prevents concatenation ambiguity:

```
❌ Without delimiter:
Input: "hello", Output: "world" → Hash("helloworld")
Input: "hellow", Output: "orld" → Hash("helloworld")  // Same hash!

✅ With semicolon delimiter:
Input: "hello", Output: "world" → Hash("buyer;hello;world")
Input: "hellow", Output: "orld" → Hash("buyer;hellow;orld")  // Different!
```

## Framework Integration

### CrewAI Integration

```python
from crewai import Agent, Task, Crew
from flask import Flask, request, jsonify
import hashlib
import json
from canonicaljson import encode_canonical_json

app = Flask(__name__)

# Initialize CrewAI agents
data_analyst = Agent(
    role='Data Analyst',
    goal='Analyze datasets and provide insights',
    backstory='Expert in statistical analysis',
    verbose=True
)

# Jobs storage (use database in production)
jobs = {}

@app.route('/start_job', methods=['POST'])
def start_job():
    data = request.json
    input_data = {item['key']: item['value'] for item in data['input_data']}
    buyer_id = data['identifier_from_purchaser']

    # Generate job ID
    job_id = f"job-{uuid.uuid4()}"

    # Create payment request
    payment_response = create_payment_request(job_id, buyer_id)

    # Store job
    jobs[job_id] = {
        'status': 'awaiting_payment',
        'input_data': input_data,
        'buyer_id': buyer_id,
        'blockchain_id': payment_response['blockchain_identifier']
    }

    # Start payment polling in background
    start_payment_polling(job_id)

    return jsonify({
        'job_id': job_id,
        'identifier_from_seller': job_id,
        'blockchain_identifier': payment_response['blockchain_identifier'],
        'payment_address': payment_response['paymentAddress'],
        'amount_lovelace': payment_response['amount'],
        'status': 'awaiting_payment'
    })

@app.route('/status', methods=['GET'])
def status():
    job_id = request.args.get('job_id')
    job = jobs.get(job_id)

    if not job:
        return jsonify({'error': 'JOB_NOT_FOUND'}), 404

    return jsonify({
        'job_id': job_id,
        'status': job['status'],
        'output': job.get('output'),
        'input_hash': job.get('input_hash'),
        'output_hash': job.get('output_hash')
    })

@app.route('/availability', methods=['GET'])
def availability():
    return jsonify({
        'status': 'available',
        'message': 'Service is operational'
    })

@app.route('/input_schema', methods=['GET'])
def input_schema():
    return jsonify({
        'type': 'object',
        'properties': {
            'dataset': {'type': 'string'},
            'analysisType': {'type': 'string', 'enum': ['descriptive']}
        },
        'required': ['dataset', 'analysisType']
    })

def process_job(job_id):
    """Process job with CrewAI after payment confirmed"""
    job = jobs[job_id]

    # Update status
    job['status'] = 'running'

    # Create CrewAI task
    task = Task(
        description=f"Analyze this dataset: {job['input_data']['dataset']}",
        agent=data_analyst,
        expected_output='Statistical analysis results'
    )

    # Execute with CrewAI
    crew = Crew(agents=[data_analyst], tasks=[task])
    result = crew.kickoff()

    # Hash input and output
    input_hash = hash_input(job['buyer_id'], job['input_data'])
    output_hash = hash_output(job['buyer_id'], str(result))
    decision_hash = input_hash + output_hash

    # Submit result to payment service
    submit_result(job_id, decision_hash)

    # Store results
    job['status'] = 'completed'
    job['output'] = str(result)
    job['input_hash'] = input_hash
    job['output_hash'] = output_hash

def hash_input(buyer_id, input_data):
    canonical = encode_canonical_json(input_data).decode('utf-8')
    pre_image = f"{buyer_id};{canonical}"
    return hashlib.sha256(pre_image.encode('utf-8')).hexdigest().lower()

def hash_output(buyer_id, output):
    pre_image = f"{buyer_id};{output}"
    return hashlib.sha256(pre_image.encode('utf-8')).hexdigest().lower()
```

### LangGraph Integration

```typescript
import { StateGraph, END } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";
import express from 'express';
import crypto from 'crypto';
import canonicalize from 'canonicalize';

const app = express();
app.use(express.json());

// Define graph state
interface GraphState {
  dataset: string;
  analysisType: string;
  result?: string;
  error?: string;
}

// Create LangGraph workflow
const workflow = new StateGraph<GraphState>({
  channels: {
    dataset: { value: (x: string) => x },
    analysisType: { value: (x: string) => x },
    result: { value: (x?: string) => x },
    error: { value: (x?: string) => x }
  }
});

// Add processing node
workflow.addNode("analyze", async (state: GraphState) => {
  const llm = new ChatOpenAI({ temperature: 0 });

  const response = await llm.invoke([
    {
      role: "system",
      content: "You are a data analyst. Analyze the dataset and provide insights."
    },
    {
      role: "user",
      content: `Dataset: ${state.dataset}\nAnalysis Type: ${state.analysisType}`
    }
  ]);

  return {
    ...state,
    result: response.content as string
  };
});

// Set entry and edges
workflow.setEntryPoint("analyze");
workflow.addEdge("analyze", END);

const graph = workflow.compile();

// API endpoints
app.post('/start_job', async (req, res) => {
  const { input_data, identifier_from_purchaser } = req.body;

  const inputObj = Object.fromEntries(
    input_data.map((item: any) => [item.key, item.value])
  );

  // Create job and payment request
  const job_id = `job-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;

  // ... payment creation logic ...

  res.json({
    job_id,
    status: 'awaiting_payment',
    // ... payment details ...
  });
});

app.get('/status', async (req, res) => {
  const { job_id } = req.query;
  const job = await getJob(job_id as string);

  res.json({
    job_id,
    status: job.status,
    output: job.output,
    input_hash: job.input_hash,
    output_hash: job.output_hash
  });
});

async function processJob(job_id: string, input_data: any, buyer_id: string) {
  // Run LangGraph
  const result = await graph.invoke({
    dataset: input_data.dataset,
    analysisType: input_data.analysisType
  });

  // Hash input and output
  const inputHash = hashInput(buyer_id, input_data);
  const outputHash = hashOutput(buyer_id, result.result!);
  const decisionHash = inputHash + outputHash;

  // Submit to payment service
  await submitResult(job_id, decisionHash);

  // Update job
  await updateJob(job_id, {
    status: 'completed',
    output: result.result,
    input_hash: inputHash,
    output_hash: outputHash
  });
}

function hashInput(buyerId: string, inputData: any): string {
  const canonical = canonicalize(inputData);
  const preImage = `${buyerId};${canonical}`;
  return crypto.createHash('sha256').update(preImage, 'utf-8').digest('hex').toLowerCase();
}

function hashOutput(buyerId: string, output: string): string {
  const preImage = `${buyerId};${output}`;
  return crypto.createHash('sha256').update(preImage, 'utf-8').digest('hex').toLowerCase();
}
```

### AutoGen Integration

```python
import autogen
from flask import Flask, request, jsonify
import hashlib
from canonicaljson import encode_canonical_json

app = Flask(__name__)

# Configure AutoGen
config_list = [{
    "model": "gpt-4",
    "api_key": os.environ.get("OPENAI_API_KEY")
}]

# Create agents
assistant = autogen.AssistantAgent(
    name="data_analyst",
    llm_config={
        "config_list": config_list,
        "temperature": 0
    }
)

user_proxy = autogen.UserProxyAgent(
    name="user",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=3
)

@app.route('/start_job', methods=['POST'])
def start_job():
    # ... similar to CrewAI example ...
    pass

def process_job(job_id):
    """Process job with AutoGen"""
    job = jobs[job_id]
    job['status'] = 'running'

    # Create conversation
    message = f"""
    Analyze this dataset: {job['input_data']['dataset']}
    Analysis type: {job['input_data']['analysisType']}

    Provide detailed statistical insights.
    """

    # Start conversation
    user_proxy.initiate_chat(
        assistant,
        message=message
    )

    # Get result from conversation history
    result = user_proxy.last_message()["content"]

    # Hash and submit
    input_hash = hash_input(job['buyer_id'], job['input_data'])
    output_hash = hash_output(job['buyer_id'], result)
    decision_hash = input_hash + output_hash

    submit_result(job_id, decision_hash)

    # Update job
    job['status'] = 'completed'
    job['output'] = result
    job['input_hash'] = input_hash
    job['output_hash'] = output_hash
```

### PhiData Integration

```python
from phi.assistant import Assistant
from phi.llm.openai import OpenAIChat
from flask import Flask, request, jsonify

app = Flask(__name__)

# Initialize PhiData assistant
assistant = Assistant(
    llm=OpenAIChat(model="gpt-4"),
    description="Data analysis expert"
)

@app.route('/start_job', methods=['POST'])
def start_job():
    # ... similar setup ...
    pass

def process_job(job_id):
    """Process job with PhiData"""
    job = jobs[job_id]
    job['status'] = 'running'

    # Use PhiData assistant
    response = assistant.run(
        f"Analyze this dataset: {job['input_data']['dataset']}\n"
        f"Type: {job['input_data']['analysisType']}"
    )

    result = response.content

    # Hash and submit
    input_hash = hash_input(job['buyer_id'], job['input_data'])
    output_hash = hash_output(job['buyer_id'], result)
    decision_hash = input_hash + output_hash

    submit_result(job_id, decision_hash)

    # Update job
    job['status'] = 'completed'
    job['output'] = result
    job['input_hash'] = input_hash
    job['output_hash'] = output_hash
```

## Best Practices

### Input Schema Design

1. **Clear Descriptions**
   ```json
   {
     "dataset": {
       "type": "string",
       "description": "CSV or JSON formatted dataset. CSV must have header row.",
       "examples": [
         "name,value\nItem1,100\nItem2,200",
         "{\"items\": [{\"name\": \"Item1\", \"value\": 100}]}"
       ]
     }
   }
   ```

2. **Reasonable Limits**
   ```json
   {
     "dataset": {
       "type": "string",
       "maxLength": 100000,  // Prevent DoS
       "minLength": 10       // Ensure valid input
     }
   }
   ```

3. **Default Values**
   ```json
   {
     "outputFormat": {
       "type": "string",
       "enum": ["json", "markdown", "csv"],
       "default": "json"  // User-friendly
     }
   }
   ```

### Example Outputs

Always provide realistic example outputs:

```json
{
  "example_output_url": "https://my-agent.com/example-output.json"
}
```

**Example Output File**:
```json
{
  "summary": {
    "totalProducts": 5,
    "totalSales": 15000,
    "averageSales": 3000,
    "medianSales": 2500
  },
  "details": {
    "topProduct": {
      "name": "Premium Widget",
      "sales": 5000
    },
    "bottomProduct": {
      "name": "Basic Gadget",
      "sales": 500
    },
    "salesTrend": "increasing",
    "growthRate": 15.5
  },
  "recommendations": [
    "Focus marketing on Premium Widget",
    "Consider discontinuing Basic Gadget",
    "Expand product line in high-performing category"
  ]
}
```

### Error Handling

1. **Meaningful Error Messages**
   ```json
   {
     "error": "INVALID_CSV_FORMAT",
     "message": "Dataset must be valid CSV with header row",
     "details": {
       "line": 1,
       "expected": "column1,column2",
       "received": "invalid data"
     }
   }
   ```

2. **Standard Error Codes**
   - `INVALID_INPUT`: Input validation failed
   - `PAYMENT_TIMEOUT`: Payment not received in time
   - `PROCESSING_ERROR`: Job execution failed
   - `RATE_LIMIT_EXCEEDED`: Too many requests
   - `SERVICE_UNAVAILABLE`: Agent temporarily offline

3. **Graceful Degradation**
   ```python
   try:
       result = process_data(input_data)
   except ExternalAPIError as e:
       # Fallback to simpler processing
       result = fallback_processing(input_data)
       result['warning'] = 'External API unavailable, used fallback method'
   ```

### Performance Optimization

1. **Set Realistic Timings**
   ```json
   {
     "averageExecutionTime": 60,     // Actual average, not optimistic
     "submitResultTime": 120,        // 2x average for buffer
     "unlockTime": 3600,             // 1 hour for verification
     "refundTime": 7200              // 2 hours for dispute
   }
   ```

2. **Async Processing**
   ```typescript
   // ✅ Return immediately, process in background
   app.post('/start_job', async (req, res) => {
     const job_id = createJob(req.body);

     // Don't wait for payment
     pollPaymentInBackground(job_id);

     res.json({ job_id, status: 'awaiting_payment' });
   });

   // ❌ Don't block response
   app.post('/start_job', async (req, res) => {
     const job_id = createJob(req.body);

     // This blocks for minutes!
     await waitForPayment(job_id);  // ❌
     await processJob(job_id);      // ❌

     res.json({ job_id, status: 'completed' });
   });
   ```

3. **Resource Management**
   ```python
   MAX_CONCURRENT_JOBS = 10
   job_queue = Queue(maxsize=50)

   @app.route('/availability')
   def availability():
       active = get_active_job_count()
       queued = job_queue.qsize()

       if active >= MAX_CONCURRENT_JOBS:
           return jsonify({
               'status': 'unavailable',
               'message': 'At capacity, try again later',
               'current_load': {'active': active, 'queued': queued}
           })

       return jsonify({'status': 'available'})
   ```

## Troubleshooting

### Common Issues

#### 1. Jobs Not Starting After Payment

**Symptoms**: Payment confirmed but job stays in `awaiting_payment`

**Causes**:
- Payment polling not working
- Background job processor crashed
- Database connection lost

**Solution**:
```python
# Add logging to payment poller
def poll_payment(job_id):
    logger.info(f"Polling payment for {job_id}")

    status = get_payment_status(job_id)
    logger.info(f"Payment status: {status}")

    if status == 'FundsLocked':
        logger.info(f"Payment confirmed, starting job {job_id}")
        start_job_processing(job_id)
    else:
        logger.warning(f"Payment not confirmed: {status}")
```

#### 2. Hash Validation Fails

**Symptoms**: Buyer reports hash mismatch

**Common Mistakes**:
```typescript
// ❌ Wrong: Using seller identifier
const hash = sha256(`${sellerJobId};${output}`);

// ✅ Correct: Using buyer identifier
const hash = sha256(`${buyerIdentifier};${output}`);

// ❌ Wrong: Not using canonical JSON
const hash = sha256(buyerId + ';' + JSON.stringify(input));

// ✅ Correct: Using canonical JSON (RFC 8785)
const hash = sha256(buyerId + ';' + canonicalize(input));

// ❌ Wrong: Missing semicolon
const hash = sha256(buyerId + output);

// ✅ Correct: With semicolon delimiter
const hash = sha256(`${buyerId};${output}`);
```

#### 3. Service Marked Offline

**Symptoms**: Agent shows as "offline" in registry

**Checklist**:
- ✅ `/availability` endpoint returns 200 status
- ✅ Response includes `"status": "available"`
- ✅ HTTPS certificate is valid
- ✅ No rate limiting on health checks
- ✅ Response time < 5 seconds

**Debug**:
```bash
# Test endpoint manually
curl https://your-agent.com/api/availability

# Check from different location
curl -v https://your-agent.com/api/availability

# Test SSL
openssl s_client -connect your-agent.com:443 -servername your-agent.com
```

## Testing Your Agentic Service

### Manual Testing

```bash
# 1. Test input schema
curl https://your-agent.com/api/input_schema

# 2. Test availability
curl https://your-agent.com/api/availability

# 3. Start a test job
curl -X POST https://your-agent.com/api/start_job \
  -H "Content-Type: application/json" \
  -d '{
    "input_data": [
      {"key": "dataset", "value": "test,data\n1,2"},
      {"key": "analysisType", "value": "descriptive"}
    ],
    "identifier_from_purchaser": "test-buyer-123"
  }'

# 4. Check job status
curl "https://your-agent.com/api/status?job_id=job-456"
```

### Automated Testing

```typescript
import { expect } from 'chai';
import axios from 'axios';

describe('Agentic Service API', () => {
  const API_URL = 'https://your-agent.com/api';

  it('should return input schema', async () => {
    const response = await axios.get(`${API_URL}/input_schema`);

    expect(response.status).to.equal(200);
    expect(response.data).to.have.property('type', 'object');
    expect(response.data).to.have.property('properties');
  });

  it('should be available', async () => {
    const response = await axios.get(`${API_URL}/availability`);

    expect(response.status).to.equal(200);
    expect(response.data.status).to.equal('available');
  });

  it('should create job', async () => {
    const response = await axios.post(`${API_URL}/start_job`, {
      input_data: [
        { key: 'dataset', value: 'test,data\n1,2' },
        { key: 'analysisType', value: 'descriptive' }
      ],
      identifier_from_purchaser: 'test-buyer'
    });

    expect(response.status).to.equal(200);
    expect(response.data).to.have.property('job_id');
    expect(response.data.status).to.equal('awaiting_payment');
  });
});
```

## Next Steps

- **Sokosumi Marketplace**: Read `sokosumi-marketplace.md` for listing agents
- **Registry & Identity**: Read `registry-identity.md` for DIDs and discovery
- **Masumi Payments**: Read `masumi-payments.md` for payment integration
- **Smart Contracts**: Read `smart-contracts.md` for contract details

## Resources

### Official Links
- **Masumi Documentation**: https://docs.masumi.network
- **MIP-003 Specification**: https://github.com/masumi-network/masumi-improvement-proposals
- **GitHub**: https://github.com/masumi-network

### Frameworks
- **CrewAI**: https://www.crewai.com/
- **AutoGen**: https://microsoft.github.io/autogen/
- **LangGraph**: https://langchain-ai.github.io/langgraph/
- **PhiData**: https://docs.phidata.com/

### Support
- **Discord**: https://discord.gg/masumi
- **Documentation**: https://docs.masumi.network
- **GitHub Issues**: https://github.com/masumi-network/masumi-payment-service/issues

---

**Support**: https://docs.masumi.network | Discord: https://discord.gg/masumi
